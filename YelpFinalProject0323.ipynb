{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start SPark Content\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sc = SparkSession.builder.appName(\"yelp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"review_id\",\"user_id\",\"business_id\",\"stars\",\"date\",\"text\",\"useful\",\"funny\",\"cool\"\n",
    "\n",
    "#1. Clean the dataset\n",
    "\n",
    "df = spark.read.csv( \"Yelp_review.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business_id: string (nullable = true)\n",
    "# |-- weekday: string (nullable = true)\n",
    "# |-- hour: string (nullable = true)\n",
    "# |-- checkins: string (nullable = true)\n",
    "df1 =spark.read.csv(\"yelp_checkin_1.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: string (nullable = true)\n",
      " |-- funny: string (nullable = true)\n",
      " |-- cool: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+------+-----+----+\n",
      "|           review_id|             user_id|         business_id|stars|      date|                text|useful|funny|cool|\n",
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+------+-----+----+\n",
      "|vkVSCC7xljjrAI4UG...|bv2nCi5Qv5vroFiqK...|AEx2SYEUJmTxVVB18...|    5|2016-05-28|Super simple plac...|  null| null|null|\n",
      "|Staff was very he...|                   0|                   0|    0|      null|                null|  null| null|null|\n",
      "|n6QzIUObkYshz4dz2...|bv2nCi5Qv5vroFiqK...|VR6GpWIda3SfvPC-l...|    5|2016-05-28|Small unassuming ...|  null| null|null|\n",
      "|We had their beef...|                null|                null| null|      null|                null|  null| null|null|\n",
      "|A bit outside of ...|                   0|                   0|    0|      null|                null|  null| null|null|\n",
      "|MV3CcKScW05u5LVfF...|bv2nCi5Qv5vroFiqK...|CKC0-MOWMqoeWf6s-...|    5|2016-05-28|Lester's is locat...|  null| null|null|\n",
      "|The smoked meat i...|                   0|                   0|    0|      null|                null|  null| null|null|\n",
      "|IXvOzsEMYtiJI0CAR...|bv2nCi5Qv5vroFiqK...|ACFtxLv8pGrrxMm6E...|    4|2016-05-28|Love coming here....|  null| null|null|\n",
      "|The food speaks f...| so good. Burgers...| the regular is a...| null|      null|                null|  null| null|null|\n",
      "|Getting the Cajun...|                   0|                   0|    0|      null|                null|  null| null|null|\n",
      "|L_9BTb55X0GDtThi6...|bv2nCi5Qv5vroFiqK...|s2I_Ni76bjJNK9yG6...|    4|2016-05-28|Had their chocola...|  null| null|null|\n",
      "|If you're looking...|                   0|                   0|    0|      null|                null|  null| null|null|\n",
      "|HRPm3vEZ_F-33TYVT...|_4iMDXbXZ1p1ONG29...|8QWPlVQ6D-OExqXoa...|    5|2014-09-24|Cycle Pub Las Veg...|     1|    0|   0|\n",
      "|ymAUG8DZfQcFTBSOi...|u0LXt3Uea_GidxRW1...|9_CGhHMz8698M9-Pk...|    4|2012-05-11|Who would have gu...|  null| null|null|\n",
      "|Not quite the sam...| this is the next...|                null| null|      null|                null|  null| null|null|\n",
      "|So far the only i...| chicken & vegeta...|                null| null|      null|                null|  null| null|null|\n",
      "| Next time I go back| I'm going to try...|                   0|    0|         2|                null|  null| null|null|\n",
      "|8UIishPUD92hXtScS...|u0LXt3Uea_GidxRW1...|gkCorLgPyQLsptTHa...|    4|2015-10-27|Always drove past...|  null| null|null|\n",
      "|                Cute| quaint coffee sh...|                null| null|      null|                null|  null| null|null|\n",
      "|BF ordered an ice...|                   1|                   0|    0|      null|                null|  null| null|null|\n",
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" |-- business_id: string (nullable = true)\n",
    " |-- name: string (nullable = true)\n",
    " |-- neighborhood: string (nullable = true)\n",
    " |-- address: string (nullable = true)\n",
    " |-- city: string (nullable = true)\n",
    " |-- state: string (nullable = true)\n",
    " |-- postal_code: string (nullable = true)\n",
    " |-- latitude: string (nullable = true)\n",
    " |-- longitude: string (nullable = true)\n",
    " |-- stars: string (nullable = true)\n",
    " |-- review_count: string (nullable = true)\n",
    " |-- is_open: string (nullable = true)\n",
    " |-- categories: string (nullable = true)\"\"\"\n",
    "df2 =spark.read.csv(\"yelp_business.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- stars: string (nullable = true)\n",
      " |-- review_count: string (nullable = true)\n",
      " |-- is_open: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+------------------+--------------------+--------------+-------------+-----------+-------------+--------------+------------+------------+-------+--------------------+\n",
      "|         business_id|                name|      neighborhood|             address|          city|        state|postal_code|     latitude|     longitude|       stars|review_count|is_open|          categories|\n",
      "+--------------------+--------------------+------------------+--------------------+--------------+-------------+-----------+-------------+--------------+------------+------------+-------+--------------------+\n",
      "|FYWN1wneV18bWNgQj...|\"\"\"Dental by Desi...|              null| \"\"\"4855 E Warner Rd|     Ste B9\"\"\"|    Ahwatukee|         AZ|        85044|    33.3306902|-111.9785992|         4.0|     22|                   1|\n",
      "|He-G7vWjzVUysIKrf...|\"\"\"Stephen Szabo ...|              null|\"\"\"3101 Washingto...|      McMurray|           PA|      15317|   40.2916853|   -80.1048999|         3.0|          11|      1|Hair Stylists;Hai...|\n",
      "|KQPW8lFf1y5BT2Mxi...|\"\"\"Western Motor ...|              null|  \"\"\"6025 N 27th Ave|      Ste 1\"\"\"|      Phoenix|         AZ|        85017|    33.5249025|-112.1153098|         1.5|     18|                   1|\n",
      "|8DShNS-LuFqpEWIp0...|\"\"\"Sports Authori...|              null|\"\"\"5000 Arizona M...|    Ste 435\"\"\"|        Tempe|         AZ|        85282|    33.3831468|-111.9647254|         3.0|      9|                   0|\n",
      "|PfOCPjBrlQAnz__NX...|\"\"\"Brick House Ta...|              null|  \"\"\"581 Howe Ave\"\"\"|Cuyahoga Falls|           OH|      44221|   41.1195346|   -81.4756898|         3.5|         116|      1|American (New);Ni...|\n",
      "|o9eMRCWt5PkpLDE0g...|       \"\"\"Messina\"\"\"|              null|\"\"\"Richterstr. 11\"\"\"|     Stuttgart|           BW|      70567|      48.7272|       9.14795|         4.0|           5|      1| Italian;Restaurants|\n",
      "|kCoE3jvEtg6UVz5SO...|    \"\"\"BDJ Realty\"\"\"|         Summerlin|  \"\"\"2620 Regatta Dr|    Ste 102\"\"\"|    Las Vegas|         NV|        89128|      36.20743|  -115.26846|         4.0|      5|                   1|\n",
      "|OD2hnuuTJI9uotcKy...|   \"\"\"Soccer Zone\"\"\"|              null|\"\"\"7240 W Lake Me...|      Ste 4\"\"\"|    Las Vegas|         NV|        89128|    36.1974844|-115.2496601|         1.5|      9|                   1|\n",
      "|EsMcGiZaQuG1OOvL9...|\"\"\"Any Given Sund...|              null|\"\"\"2612 Brandt Sc...|       Wexford|           PA|      15090|40.6151022445|-80.0913487465|         5.0|          15|      1|Coffee & Tea;Ice ...|\n",
      "|TGWhGNusxyMaA4kQV...|\"\"\"Detailing Gone...|              null|                \"\"\"\"|     Henderson|           NV|      89014|36.0558252127| -115.04635039|         5.0|           7|      1|Automotive;Auto D...|\n",
      "|XOSRcvtaKc_Q5H1SA...|\"\"\"East Coast Cof...|              null|\"\"\"737 West Pike ...|       Houston|           PA|      15342|40.2415480142|-80.2128151059|         4.5|           3|      0|Breakfast & Brunc...|\n",
      "|Y0eMNa5C-YU1RQOZf...|\"\"\"CubeSmart Self...|              null|\"\"\"2414 South Gil...|      Chandler|           AZ|      85286|   33.2717201|  -111.7912569|         5.0|          23|      1|Local Services;Se...|\n",
      "|xcgFnd-MwkZeO5G2H...|\"\"\"T & T Bakery a...|   Markham Village|\"\"\"35 Main Street...|       Markham|           ON|    L3P 1X3|   43.8751774|   -79.2601532|         4.0|          38|      1|Bakeries;Bagels;Food|\n",
      "|NmZtoE3v8RdSJEczY...|\"\"\"Complete Denta...|              null|\"\"\"107 Whitaker S...|     Homestead|           PA|      15120|   40.4014882|   -79.8879161|         2.0|           5|      1|General Dentistry...|\n",
      "|fNMVV_ZX7CJSDWQGd...|\"\"\"Showmars Gover...|            Uptown|  \"\"\"600 E 4th St\"\"\"|     Charlotte|           NC|      28202|   35.2216474|   -80.8393449|         3.5|           7|      1|Restaurants;Ameri...|\n",
      "|l09JfMeQ6ynYs5MCJ...|\"\"\"Alize Catering\"\"\"|Yonge and Eglinton| \"\"\"2459 Yonge St\"\"\"|       Toronto|           ON|    M4P 2H6|   43.7113993|   -79.3993388|         3.0|          12|      0|Italian;French;Re...|\n",
      "|IQSlT5jGE6CCDhSG0...|\"\"\"T & Y Nail Spa\"\"\"|              null|\"\"\"8411 W Thunder...|   Unit 101\"\"\"|       Peoria|         AZ|        85381|    33.6086538|-112.2400118|         3.0|     20|                   1|\n",
      "|b2I2DXtZVnpUMCXp1...|\"\"\"Meineke Car Ca...|              null|\"\"\"2518 Ironwood ...|   Sun Prairie|           WI|      53590|     43.18508|    -89.262047|         3.5|           9|      1|Tires;Oil Change ...|\n",
      "|0FMKDOU8TJT1x87OK...|\"\"\"Senior's Barbe...|              null|\"\"\"13375 W McDowe...|      Goodyear|           AZ|      85395|    33.463629|   -112.347038|         5.0|          65|      1|Barbers;Beauty & ...|\n",
      "|Gu-xs3NIQTj3Mj2xY...|\"\"\"Maxim Bakery &...|              null|\"\"\"9665 Bayview A...|   Unit 1-4\"\"\"|Richmond Hill|         ON|      L4C 9V4|    43.8675648| -79.4126618|         3.5|     34|                   1|\n",
      "+--------------------+--------------------+------------------+--------------------+--------------+-------------+-----------+-------------+--------------+------------+------------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- checkins: string (nullable = true)\n",
      "\n",
      "+--------------------+-------+-----+--------+\n",
      "|         business_id|weekday| hour|checkins|\n",
      "+--------------------+-------+-----+--------+\n",
      "|3Mc-LxcqeguOXOVT_...|    Tue| 0:00|      12|\n",
      "|SVFx6_epO22bZTZnK...|    Wed| 0:00|       4|\n",
      "|vW9aLivd4-IorAfSt...|    Tue|14:00|       1|\n",
      "|tEzxhauTQddACyqdJ...|    Fri|19:00|       1|\n",
      "|CEyZU32P-vtMhgqRC...|    Tue|17:00|       1|\n",
      "|9dn5pee_n2dWQfN57...|    Sun| 3:00|       5|\n",
      "|6Zk5F7fsTr8n2CJTl...|    Wed| 1:00|       4|\n",
      "|OE_IDW5w_W97sBcZv...|    Sat| 1:00|       1|\n",
      "|gy5pr5bFAjOL5rERS...|    Sat|15:00|       1|\n",
      "|r2-eAhGANXlcgQy89...|    Mon|19:00|       1|\n",
      "|wiBxwslJAGDdZ2nmL...|    Mon|16:00|       1|\n",
      "|08jURVR_eDvXq9scd...|    Sat|23:00|       1|\n",
      "|BlWPjh2WuvQSlmYmg...|    Sun| 0:00|       1|\n",
      "|6DO_2jivyxcL6SXGP...|    Wed|23:00|       1|\n",
      "|wrJROwvVKHvdMVIZO...|    Thu|21:00|       3|\n",
      "|uU8up3hGwW9qnzQD1...|    Fri| 0:00|       1|\n",
      "|JHPq9KvMuJaC7CPAT...|    Sun|16:00|       1|\n",
      "|vyzfT3_KzLi8WmInw...|    Thu| 9:00|       1|\n",
      "|E4T0rQBJa0e4HIliB...|    Thu|23:00|       2|\n",
      "|vuvnexwJzb1ydKLac...|    Mon|18:00|       1|\n",
      "+--------------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[review_id: string, user_id: string, business_id: string, stars: string, date: string, text: string, useful: string, funny: string, cool: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           review_id|             user_id|         business_id|stars|      date|                text|              useful|               funny|                cool|label|\n",
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|HRPm3vEZ_F-33TYVT...|_4iMDXbXZ1p1ONG29...|8QWPlVQ6D-OExqXoa...|    5|2014-09-24|Cycle Pub Las Veg...|                   1|                   0|                   0|  5.0|\n",
      "|Ia-w-nR1FrlzsiuEi...|u0LXt3Uea_GidxRW1...|Eox_Qq74oaFZ-Yjth...|    3|2011-07-18|Service is really...|                   1|                   1|                   1|  3.0|\n",
      "|hkyyWaX-EMiIkvyu1...|nsOf58RZjMTn8V94E...|djyIZW8gVNWby8wau...|    5|2017-08-23|Suzanne was able ...|                   0|                   0|                   0|  5.0|\n",
      "|BF0ANB54sc_f-3_ho...|ssuXFjkH4neiBgwv-...|JlNeaOymdVbE6_bub...|    1|2014-08-09|We always go to t...|                   3|                   0|                   0|  1.0|\n",
      "|DbLUpPT61ykLTakkn...|ssuXFjkH4neiBgwv-...|0Rni7ocMC_Lg2UH0l...|    1|2014-08-09|This place is alw...|                   6|                   0|                   0|  1.0|\n",
      "|40sWchjx-4rQ273cb...|ssuXFjkH4neiBgwv-...|3uBrRcIhbhed1xftL...|    1|2015-08-23|Horrible customer...|                   5|                   0|                   0|  1.0|\n",
      "|UXmBQNWMD1PBLDC_n...|xJbxpra6iyCsph35P...|0g7Pr8OWl_t_7DUeY...|    1|2014-02-03|I bought a groupo...|                   1|                   3|                   0|  1.0|\n",
      "|QYw2OurOBplkQRCpY...|nOTl4aPC4tKHK35T3...|XCxxPZ3Lu5mwmIo7I...|    4|2016-01-24|This place is alw...|                   0|                   0|                   0|  4.0|\n",
      "|udzzB55YAxWEfVmkc...|nOTl4aPC4tKHK35T3...|VTs4f6LnUMHD4ysOe...|    4|2012-07-08|Sometimes it feel...|                   1|                   0|                   0|  4.0|\n",
      "|raUmEc0rdycXSRwXS...|nOTl4aPC4tKHK35T3...|g-OTq2Jb7FRP7cYDU...|    3|2012-04-15|I have since swit...|                   3|                   1|                   0|  3.0|\n",
      "|cd5K0jPd7Gv29x_h1...|nOTl4aPC4tKHK35T3...|pOvTYClFgMm-wAXPW...|    2|2016-05-22|I have eaten at s...|                   1|                   0|                   0|  2.0|\n",
      "|PRj0OFgJjN5ljpeDs...|nOTl4aPC4tKHK35T3...|6Q7-wkCPc1KF75jZL...|    2|2012-08-22|\"Okay, so from wh...|          NOT Circus| Circus Manor Mot...| such as internet...|  2.0|\n",
      "|f17tpJXCwTE0M137d...|nOTl4aPC4tKHK35T3...|zgQHtqX0gqMw1nlBZ...|    2|2013-10-19|\"While I really e...|   greasy appetizers| this is the righ...| I can't stress e...|  2.0|\n",
      "|-FV47bShEgvxQCoh9...|nOTl4aPC4tKHK35T3...|bKh66jlEqEKZZFkjW...|    4|2015-09-21|\"Came here with m...| covered with fru...| which is your ba...|               toast|  4.0|\n",
      "|iJ5iOBh7bMKMtF9j-...|nOTl4aPC4tKHK35T3...|GNEjlH_KssnJVRtqV...|    4|2011-12-20|\"Our friends got ...| which I found to...| although other p...| but I can't reme...|  4.0|\n",
      "|iX6GLmUf6W81zGaiZ...|nOTl4aPC4tKHK35T3...|L6R2Op88NkoG1EGxl...|    4|2014-10-17|A little on the p...|                   0|                   0|                   0|  4.0|\n",
      "|iPqFD9u2K2KRK99tc...|nOTl4aPC4tKHK35T3...|h0TKP2PK0QaAqvqdI...|    4|2015-02-07|\"Went here with m...| for such a small...|               clean| etc. Only proble...|  4.0|\n",
      "|S0zj-QZbrbPmfBxpN...|nOTl4aPC4tKHK35T3...|lFPNibSaYC3Vq4PCG...|    3|2011-04-03|This is a newer l...|                   0|                   0|                   0|  3.0|\n",
      "|Nr4t4NobdlKx9HLMl...|nOTl4aPC4tKHK35T3...|qOuoI7hvzBAzF1Y43...|    4|2016-12-18|Been here twice n...|                   0|                   0|                   0|  4.0|\n",
      "|TaZPNqRUwK47VDE17...|nOTl4aPC4tKHK35T3...|5N8R7ALESZ30EoAzV...|    5|2016-10-17|Went in on a whim...|                   0|                   0|                   0|  5.0|\n",
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: string (nullable = true)\n",
      " |-- funny: string (nullable = true)\n",
      " |-- cool: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df = df.withColumnRenamed(\"stars\", \"label\")\n",
    "df = df.withColumn(\"label\", df[\"stars\"].cast(\"double\"))\n",
    "#df = df.where(col(\"label\").isNotNull())\n",
    "df = df.dropna(subset=['label', 'text', 'funny', 'cool',\"useful\"])\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|Cycle Pub Las Veg...|  5.0|\n",
      "|Service is really...|  3.0|\n",
      "|Suzanne was able ...|  5.0|\n",
      "|We always go to t...|  1.0|\n",
      "|This place is alw...|  1.0|\n",
      "|Horrible customer...|  1.0|\n",
      "|I bought a groupo...|  1.0|\n",
      "|This place is alw...|  4.0|\n",
      "|Sometimes it feel...|  4.0|\n",
      "|I have since swit...|  3.0|\n",
      "|I have eaten at s...|  2.0|\n",
      "|\"Okay, so from wh...|  2.0|\n",
      "|\"While I really e...|  2.0|\n",
      "|\"Came here with m...|  4.0|\n",
      "|\"Our friends got ...|  4.0|\n",
      "|A little on the p...|  4.0|\n",
      "|\"Went here with m...|  4.0|\n",
      "|This is a newer l...|  3.0|\n",
      "|Been here twice n...|  4.0|\n",
      "|Went in on a whim...|  5.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select('text', 'label')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|This place is alw...|  4.0|\n",
      "|Sometimes it feel...|  4.0|\n",
      "|I have eaten at s...|  2.0|\n",
      "|\"Okay, so from wh...|  2.0|\n",
      "|\"While I really e...|  2.0|\n",
      "|\"Came here with m...|  4.0|\n",
      "|\"Our friends got ...|  4.0|\n",
      "|A little on the p...|  4.0|\n",
      "|\"Went here with m...|  4.0|\n",
      "|Been here twice n...|  4.0|\n",
      "|We stopped in her...|  4.0|\n",
      "|I often stop here...|  4.0|\n",
      "|Not much here oth...|  4.0|\n",
      "|I hiked this cany...|  4.0|\n",
      "|Holy portion size...|  4.0|\n",
      "|Flavor was actual...|  4.0|\n",
      "|I don't do ice cr...|  4.0|\n",
      "|I ate here with a...|  4.0|\n",
      "|As a vegetarian, ...|  2.0|\n",
      "|\"The only downsid...|  4.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df.filter(df.label.isin(2.0,4.0))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|This place is alw...|  4.0|\n",
      "|Sometimes it feel...|  4.0|\n",
      "|I have eaten at s...|  2.0|\n",
      "|\"Okay, so from wh...|  2.0|\n",
      "|\"While I really e...|  2.0|\n",
      "|\"Came here with m...|  4.0|\n",
      "|\"Our friends got ...|  4.0|\n",
      "|A little on the p...|  4.0|\n",
      "|\"Went here with m...|  4.0|\n",
      "|Been here twice n...|  4.0|\n",
      "|We stopped in her...|  4.0|\n",
      "|I often stop here...|  4.0|\n",
      "|Not much here oth...|  4.0|\n",
      "|I hiked this cany...|  4.0|\n",
      "|Holy portion size...|  4.0|\n",
      "|Flavor was actual...|  4.0|\n",
      "|I don't do ice cr...|  4.0|\n",
      "|I ate here with a...|  4.0|\n",
      "|As a vegetarian, ...|  2.0|\n",
      "|\"The only downsid...|  4.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.limit(1000)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 ML pipeline\n",
    "tokenizer = Tokenizer(inputCol = \"text\", outputCol = \"words\") \n",
    "TF = HashingTF(inputCol = tokenizer.getOutputCol(), outputCol = \"tfFeatures\")\n",
    "idf = IDF(inputCol = \"tfFeatures\",outputCol = \"features\")\n",
    "lr = LogisticRegression(maxIter = 10, regParam = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages = [tokenizer,TF,idf,lr])\n",
    "model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#3. Test data set, unlabeled (id, text)\n",
    "test = spark.createDataFrame([\n",
    "     (4, \"Worst restaurant ever\"),\n",
    "     (5, \"This restaurant is absolutely the best\"),\n",
    "     (6, \"best hotel ever\"),\n",
    "     (7, \"I love this hotel\")\n",
    "     ],[\"id\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, Worst restaurant ever) --> prediction = 2.000000 probability =[0.0011268009173979953,0.0011268009173979953,0.49915003742199504,0.0011268009173979953,0.4974695598258109]\n",
      "(5, This restaurant is absolutely the best) --> prediction = 4.000000 probability =[0.0006235246950701271,0.0006235246950701271,0.08555191769563698,0.0006235246950701271,0.9125775082191526]\n",
      "(6, best hotel ever) --> prediction = 4.000000 probability =[0.0008863673087221466,0.0008863673087221466,0.1819838549889905,0.0008863673087221466,0.815357043084843]\n",
      "(7, I love this hotel) --> prediction = 4.000000 probability =[0.0007918249925373259,0.0007918249925373259,0.13696054669456556,0.0007918249925373259,0.8606639783278225]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#4. Make Prediction\n",
    "prediction = model.transform(test)\n",
    "\n",
    "selected = prediction.select(\"id\",\"text\",\"probability\",\"prediction\")\n",
    "for row in selected.collect():\n",
    "    id, text, prob, pred = row\n",
    "    print(\"(%d, %s) --> prediction = %f probability =%s\" %(id, text, pred, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, text: string, words: array<string>, tfFeatures: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkins\n",
      "After Scaling :\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# UDF for converting column type from vector to double type\n",
    "unlist = udf(lambda x: list(x)[0])\n",
    "\n",
    "# Iterating over columns to be scaled\n",
    "for i in [\"checkins\"]:\n",
    "    # VectorAssembler Transformation - Converting column to vector type\n",
    "    assembler = VectorAssembler(inputCols=[i],outputCol=i+\"_Vect\")\n",
    "\n",
    "    # MinMaxScaler Transformation\n",
    "    scaler = MinMaxScaler(inputCol=i+\"_Vect\", outputCol=i+\"_Scaled\")\n",
    "\n",
    "    # Pipeline of VectorAssembler and MinMaxScaler\n",
    "    pipeline = Pipeline(stages=[assembler, scaler])\n",
    "\n",
    "    # Fitting pipeline on dataframe\n",
    "    df1 = pipeline.fit(df1).transform(df1).withColumn(i+\"_Scaled\", unlist(i+\"_Scaled\")).drop(i+\"_Vect\")\n",
    "    print(i)\n",
    "\n",
    "print(\"After Scaling :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1= df1[\"checkins\"].cast(\"double\")\n",
    "df1 = df1.withColumn(\"checkins\", df1[\"checkins\"].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+--------+\n",
      "|         business_id|weekday| hour|checkins|\n",
      "+--------------------+-------+-----+--------+\n",
      "|3Mc-LxcqeguOXOVT_...|    Tue| 0:00|    12.0|\n",
      "|SVFx6_epO22bZTZnK...|    Wed| 0:00|     4.0|\n",
      "|vW9aLivd4-IorAfSt...|    Tue|14:00|     1.0|\n",
      "|tEzxhauTQddACyqdJ...|    Fri|19:00|     1.0|\n",
      "|CEyZU32P-vtMhgqRC...|    Tue|17:00|     1.0|\n",
      "|9dn5pee_n2dWQfN57...|    Sun| 3:00|     5.0|\n",
      "|6Zk5F7fsTr8n2CJTl...|    Wed| 1:00|     4.0|\n",
      "|OE_IDW5w_W97sBcZv...|    Sat| 1:00|     1.0|\n",
      "|gy5pr5bFAjOL5rERS...|    Sat|15:00|     1.0|\n",
      "|r2-eAhGANXlcgQy89...|    Mon|19:00|     1.0|\n",
      "|wiBxwslJAGDdZ2nmL...|    Mon|16:00|     1.0|\n",
      "|08jURVR_eDvXq9scd...|    Sat|23:00|     1.0|\n",
      "|BlWPjh2WuvQSlmYmg...|    Sun| 0:00|     1.0|\n",
      "|6DO_2jivyxcL6SXGP...|    Wed|23:00|     1.0|\n",
      "|wrJROwvVKHvdMVIZO...|    Thu|21:00|     3.0|\n",
      "|uU8up3hGwW9qnzQD1...|    Fri| 0:00|     1.0|\n",
      "|JHPq9KvMuJaC7CPAT...|    Sun|16:00|     1.0|\n",
      "|vyzfT3_KzLi8WmInw...|    Thu| 9:00|     1.0|\n",
      "|E4T0rQBJa0e4HIliB...|    Thu|23:00|     2.0|\n",
      "|vuvnexwJzb1ydKLac...|    Mon|18:00|     1.0|\n",
      "+--------------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-4d5a52630ce7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coerce'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mis_scalars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mis_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\generic.py\u001b[0m in \u001b[0;36m_check\u001b[1;34m(cls, inst)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minst\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_typ\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\users\\Sathya\\Spark\\python\\pyspark\\sql\\column.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m         raise ValueError(\"Cannot convert column into bool: please use '&' for 'and', '|' for 'or', \"\n\u001b[0m\u001b[0;32m    702\u001b[0m                          \"'~' for 'not' when building DataFrame boolean expressions.\")\n\u001b[0;32m    703\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions."
     ]
    }
   ],
   "source": [
    "print(pd.to_numeric(df1.checkins, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-a0ca777c0fdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coerce'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#0     True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#1    False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#2     True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Name: b, dtype: bool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mis_scalars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mis_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\generic.py\u001b[0m in \u001b[0;36m_check\u001b[1;34m(cls, inst)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minst\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_typ\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\users\\Sathya\\Spark\\python\\pyspark\\sql\\column.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m         raise ValueError(\"Cannot convert column into bool: please use '&' for 'and', '|' for 'or', \"\n\u001b[0m\u001b[0;32m    702\u001b[0m                          \"'~' for 'not' when building DataFrame boolean expressions.\")\n\u001b[0;32m    703\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions."
     ]
    }
   ],
   "source": [
    "print (pd.to_numeric(df1.checkins, errors='coerce').notnull())\n",
    "#0     True\n",
    "#1    False\n",
    "#2     True\n",
    "#Name: b, dtype: bool\n",
    "\n",
    "df1 = df1[pd.to_numeric(df1.checkins, errors='coerce').notnull()]\n",
    "print (df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
